## 1. 최적화와 수리계획법
### Optimization, 최적화
- 여러 실행가능(feasible = 제약식, constraints)한
<br> 대안(alternatives = 의사결정변수, decision variables)들 중에
<br> 정해진 대안평가 기준(목적식, objective function)에 근거하여
<br> 최선의 대안을 선택(목적식을 최대화, 최소화하는 의사결정변수들의 값을 결정)하는 의사결정 과정
- 특정의 집합 위에서 정의된 실수값, 함수, 정수에 대해 그 값이 최대나 최소가 되는 상태를 해석하는 문제
<br> 많은 경우 머신러닝 문제는 최적화 문제로 귀결됨

### 최적화 및 수리계획법 모형 개요
- decision variables, 의사결정 변수들
<br> 의사결정과 관련된 대안들 ex)봄학기에 학생 C의 수강과목목록
- objective function, 목적함수
<br> 의사결정변수들의 함수로 표현 ex)봄학기의 기대학점 최대화
- constraints, 제약식 : 의사결정변수들에 대한 제약들
<br> 의사결정변수들에 대한 제약들 ex)과목선택시 선수과목 이수 필수

- Mathematical Programming Models, 수리 계획법 모형
<br> 제약식들을 모두 만족하면서 목적식을 최대화, 최소화 하는 xbar의 값을 결정
<br> ex) 2차원 공간에서 linear 함수를 SSE로 찾을 때는, 모든 직선들이 대안이 되므로 제약식은 '실수여야 한다' 정도 있다. 오차제곱합이 가장 작은 답을 찾으면 정답.

## 2. 미적분 기초
### derivative, 미분
- f'(x) = 접선의 기울기, 순간변화율, 기울기의 부호는 증가함수
- sigmoid function(?)

### partial derivative, 편미분
- 변수가 두개 이상일 경우

### Gradient, 그래디언트, ∇f
## Gradient descent
- x로부터 f의 값이 가장 가파르게 증가(steepest ascent)하는 방향
- 매 단계마다 모든 Training Set를 활용
- 벡터의 크기는 증가의 가파른 정도를 의미
```
repeat until convergence{
  𝜃𝑗:=𝜃𝑗−𝛼 ∂/∂𝜃𝑗 𝐽(𝜃0,𝜃1)
]
```
- := : "Assignment Operator (대입 연산자)
- 𝛼 : Learning Rate (학습 속도)
<br> 언덕에서 내려갈 때 얼마나 큰 걸음으로 걸을 것인가를 나타내는 양의 상수
<br> 𝛼가 클수록 step이 커짐
- ∂/∂𝜃𝑗 𝐽(𝜃0,𝜃1) : Derivative Term (미분 계수)
<br> 비용함수를 𝜃에 대해 미분한 함수

## Derivate Term, 미분계수
- 우리는 결국 𝐽(𝜃1) 이 최소가 되는 실수 𝜃1을 구해야 함. 𝜃1을 초기값으로 최소값을 찾아나갈 때, ∂/∂𝜃𝑗 𝐽(𝜃1)부분은 미분계수, 즉, x가 𝜃1일 때 함수의 기울기 임.
<br> ex) 최소값 오른쪽에 𝜃1이 위치한다고 가정.
<br> 𝛼 > 0, ∂/∂𝜃𝑗𝐽(𝜃1) > 0. 결론, 𝜃1값에서 위 값들이 빠지면서 왼쪽으로 이동하면서 반복하게 된다.

## Learning Rate, 학습 속도
- 𝛼 is too smail, gradient descent can be slow.
- 𝛼 is too large, gradient descent can overshoot the minimum.
<br> It may fail to converge, or even diverge.
> 위의 두개의 변수를 같이 사용하지 않으면, 최소값으로 수렴하지 않았음에도 제자리에서 진동하는 경우가 발생할 수 있음. 𝛼가 fix되어 있어도, 𝐽(𝜃1)가 감소하므로 최소값으로 향하게 되므로 우리로 하여금 강제적으로 𝛼를 줄이는 수고를 덜게 됨.

## 3. 비선형 계획법 개요
### 최적해 : 극소점, 극대점
- Local maximum, Local minimum
- Global maximum, Global minimum

### Stationary Points, 안정점
- For a single variable function f(x)'s stationary point : f'(x)=0
- For a multi-variable function f(x)'s stationary point : ∇f(x)=0

### Saddle point, 안장점
- 다변수 함수에서 어느 방향에서 보면 극대점이지만, 다른방향에서 보면 극소점이 되는 점

## 4. 수치 최적화 알고리즘
### Numerical Optimization Algorithms
- Q. Global minimum이 어디있을까?
<br> Initial solution : 어느 point에서 시작할까?
<br> Sign of derivative : ∇f 방향은?
<br> Learning rate : 𝛼는 몇으로 fix할까?
- A. 임의의 x지점으로부터 gradient의 반대반향으로 진행하면서,
<br> gradient가 0에 가까워질 때까지, saddle point

### 머신러닝과 경사하강법
- 머신러닝에서는 traning set를 활용하여 model의 최적 feature를 traning시켜주는 것이 중요
- 적절한 feature를 찾는 방법 중 하나가 경사하강법.
- 학습이란?
<br> 임의의 weight로 예측치를 확인해보고, 실측치와 비교해보고, 오차를 좁히기 위해 단계마다 weight를 변경하는 과정
- SSE를 최소화하기 위한 weight들을(b0, b1) 결정하기 위한 노력

### Batch
- Full-batch gradient descent, 경사하강법
<br> 학습데이터 모두 사용
- Stochastic gradient descent, 확률 경사하강법
<br> 매단계마다 업데이트해야 하는 매개변수와 데이터가 너무 크다면, 무작위로 하나만 선택해서 weight, 매개변수 업데이트.
- Mini-batch gradient descent, 미니배치 경사하강법
<br> 극단적으로 하나보다는 여러 개가 낫지 않을까? 무작위로 일부만 선택해서 업데이트 하는 방식.

### 경사하강법 예시
- data 입력 -> weight 설정 -> (실측치-예측치)^2, SSE 확인 -> gradient 확인 -> feedback -> weight 재설정
- Full-batch gradient descent, Saddle point까지 반복
<br><img src="https://user-images.githubusercontent.com/89369520/140603358-883f0c93-5089-4aaa-b2d2-87790591bcc7.png" width="600">
- Visualization
<br><img src="https://user-images.githubusercontent.com/89369520/140603612-6407cf14-ce72-4564-8400-9790c04f9a9f.png" width="600">

### 경사하강법 확장
- Momentum : 관성, 가속도 개념 추가. 현재 경사 뿐 아니라 이전에 어떻게 움직였는지를 참고하여 앞으로의 학습률을 조절. 학습 방향에 대한 안정성을 개선함.
- Adagard : 변수마다 learning rate를 다르게 적용
- RMSProp : Adagard를 보완. 많이 변화하지 않은 변수들은 learning rate를 크게 하고, 많이 변화한 변수들은 learning rate를 적게 함. 학습률에 대한 안정성을 개선함.
- AdaDelta : Adagard 단점 보완(?)
- *Adam* : RMSProp + Momentum (많이 쓰임)

## 5. 라그랑지 승수와 제약식 있는 최적화
(차후 추가 설명)
