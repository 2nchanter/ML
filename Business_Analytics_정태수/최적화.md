## 최적화와 수리계획법
### Optimization, 최적화
- 여러 실행가능(feasible = 제약식, constraints)한
<br> 대안(alternatives = 의사결정변수, decision variables)들 중에
<br> 정해진 대안평가 기준(목적식, objective function)에 근거하여
<br> 최선의 대안을 선택(목적식을 최대화, 최소화하는 의사결정변수들의 값을 결정)하는 의사결정 과정
- 특정의 집합 위에서 정의된 실수값, 함수, 정수에 대해 그 값이 최대나 최소가 되는 상태를 해석하는 문제
<br> 많은 경우 머신러닝 문제는 최적화 문제로 귀결됨

### 최적화 및 수리계획법 모형 개요
- decision variables, 의사결정 변수들
<br> 의사결정과 관련된 대안들 ex)봄학기에 학생 C의 수강과목목록
- objective function, 목적함수
<br> 의사결정변수들의 함수로 표현 ex)봄학기의 기대학점 최대화
- constraints, 제약식 : 의사결정변수들에 대한 제약들
<br> 의사결정변수들에 대한 제약들 ex)과목선택시 선수과목 이수 필수

- Mathematical Programming Models, 수리 계획법 모형
<br> 제약식들을 모두 만족하면서 목적식을 최대화, 최소화 하는 xbar의 값을 결정
<br> ex) 2차원 공간에서 linear 함수를 SSE로 찾을 때는, 모든 직선들이 대안이 되므로 제약식은 '실수여야 한다' 정도 있다. 오차제곱합이 가장 작은 답을 찾으면 정답.

## 미적분 기초
### derivative, 미분
- f'(x) = 접선의 기울기, 순간변화율, 기울기의 부호는 증가함수
- sigmoid function(?)

### partial derivative, 편미분
- 변수가 두개 이상일 경우

### Gradient, 그래디언트, ∇f
## Gradient descent
- x로부터 f의 값이 가장 가파르게 증가(steepest ascent)하는 방향
- 벡터의 크기는 증가의 가파른 정도를 의미
```
repeat until convergence{
  𝜃𝑗:=𝜃𝑗−𝛼 ∂/∂𝜃𝑗 𝐽(𝜃0,𝜃1)
]
```
- := : "Assignment Operator (대입 연산자)
- 𝛼 : Learning Rate (학습 속도)
<br> 언덕에서 내려갈 때 얼마나 큰 걸음으로 걸을 것인가를 나타내는 양의 상수
<br> 𝛼가 클수록 step이 커짐
- ∂/∂𝜃𝑗 𝐽(𝜃0,𝜃1) : Derivative Term (미분 계수)
<br> 비용함수를 𝜃에 대해 미분한 함수

## Derivate Term, 미분계수

## 비선형 계획법 개요
 
## 수치 최적화 알고리즘
 
## 라그랑지 승수와 제약식 있는 최적화
