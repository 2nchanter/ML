## 로지스틱 회귀분석
### 배경
#### 알고리즘 종류
- Decision Tree : 의사결정나무, x, y축과 평행한 특징
- **Logistic Regression : 직선**
- Random Forest : 여러 알고리즘이 섞임
- SVM(Gaussian Kernel) : 비선형
- Neural Network : hidden node를 적게 가져가면 logistic, 직선과 비슷
>하나의 문제를 풀어내는 방식이 여러 가지 존재하기 때문에 위와 같은 알고리즘들이 존재하며, 어떤 모델도 best가 될 수 있기 때문에 어느정도의 알고리즘은 채용해봐야 함

#### Ex)
- 33명의 성인 여성에 대한 나이와 혈압 사이의 관계를 보자.
- 나이와 혈압 사이의 관계는 대략적으로 선형 관계가 존재한다고 할 수 있다.
<br><img width="300" src="https://user-images.githubusercontent.com/89369520/141037043-f33139ea-64b6-49eb-b901-18e1384b10b8.png">
- 이때 연속형 변수가 아닌 **Binary, 이진형** 변수인 Cancer Diagnosis를 사용한다면? 두 변수 사이의 관계식은 선형이라고 볼 수 없음.
<br><img width="300" src="https://user-images.githubusercontent.com/89369520/141037154-b1a99109-8da5-4c36-88d2-7fef763a9364.png">
- Q. 종속변수가 이진변수일 때 linear regression으로 X와 Y의 관계를 찾는것이 적합할까? (Linear regression : X와 Y를 **가장 잘 설명하는 함수 식**을 찾는 것, 연속형에서 미지의 X를 주었을 때, Y의 평균값을 추정값으로 보여주는 방식)
- A. No. logistic에서는 Y값이 아니라 binary인 label을 얻고자 하므로, **label을 가장 잘 구분하는 식**을 찾는쪽이 옳다.

### 알고리즘
#### Logistic f. (sigmoid f.)
- <img width="300" src="https://user-images.githubusercontent.com/89369520/141041613-63696b73-c1fb-4c8a-a04b-dd8bef7ff2e5.png">
- 목적 : 이진형 (0 or 1)dml 형태를 갖는 종속변수 분류문제에 대해 회귀식의 형태로 모형을 추정하는 것
- σ(z) = 1(1+e^(-z))
- x축 : z, 분류경계선 = b0 + b1xq + b2x2
- y축 : σ, sigmoid 함수값 = label 1로 Y가 분류될 수 있는 확률
- σ(함수값)은 label에 대한 확률이기 때문에 값이 0과 1 사이이다.
<br> z값이 0일 때, σ(함수값)는 0.5이다.
<br> z가 양수일수록 분모가 작아져 σ가 큰 값이 나온다.
<br> Y=1일 확률과 Y=0일 확률이 같은 지점, 즉, x에 데이터를 넣었을 때 z값이 0이 나오는 지점을 모으면 분류경계선, 회귀식이 된다.

#### 어떤 모델이 더 좋은가?
<img width="600" src="https://user-images.githubusercontent.com/89369520/141042916-f079605a-eabc-44c3-adb6-5209cfa7f4d0.png">

### 결과해석
#### 
<img width="600" src="https://user-images.githubusercontent.com/89369520/141042582-4ecac333-6ac5-4328-9137-dfca7c11bc27.png">



