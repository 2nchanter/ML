## Decision Tree
<img width="500" src="https://user-images.githubusercontent.com/89369520/143187086-59c5c881-0beb-4c0a-8370-94c69242a5ea.png">

### 의사결정나무
#### Decision Tree?
- feature들로 기준을 만들고, sample을 분류하고, 분류된 집단의 성질을 통하여 추정
- if-then 형식으로 표현되는 규칙
- 데이터 공간의 불순도가 감소하게끔 영역을 구분
<br> - 장점 : 해석력이 높으며, 직관적, 범용성이 높다.
<br> - 단점 : 변동성이 높고, 샘플에 민감하다.

#### Decision Tree를 이용한 분류법
- 여러 독립변수 중 하나의 독립변수를 선택하고 그 독립변수의 기준값(threshold)을 결정
- Recursive Partitioning(재귀적 분할)
<br>  -분할 후 같은 클래스에 속하는 데이터들의 비율이 높아지도록 두 그룹으로 분할.
<br> - leaf(child node가 없는 말단) node의 불순도가 0이 될 때까지 진행.
- Pruning the Tree(가지치기)
<br> - overfitting 방지 목적으로, 주변 가지를 없애서 tree를 단순화 시킴.

#### impurity 지표
- Entropy
<br> <img width="500" src="https://user-images.githubusercontent.com/89369520/143189889-2e61c9a1-009d-475b-bdb3-5b5849d5beae.png">
- Gini Index
<br> <img width="500" src="https://user-images.githubusercontent.com/89369520/143190014-faf0e44b-32c7-418c-a5ed-ed49b4efdb29.png">
