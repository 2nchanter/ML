# 선형회귀분석
## Prediction, 예측
### 예측이란?
- 과거의 정보로부터 설명변수 X와 반응변수 Y와의 함수관계 f(x)를 추정하여, 새로운 설명변수에 대해 예상된 연속형 결과변수 값

### 예측 vs 분류
- 연속형 변수 : 숫자로 측정 가능한 변수 ex) 온도, 압력, 가격 등 - regression model (예측)
- 범주형 변수 : 숫자의 의미가 없는 변수 ex) 불량여부(Y/N), 환자/정상 등 - classification model (분류)

### 예측모형 개요
- x에서 가능한 y값들의 평균 값을 예측치로 준다.

## Linear Regression, (다중) 선형 회귀모형
### 1. 선형회귀모델 개요
### 회귀분석
- 두 변수 간의 관계를 설명 가능한가?
<br> a. 상관분석 : 변수 사이에 의미 있는 상관관계가 있는지, 없는지 그 크기를 분석. (선형성 확인, 피어슨 상관계수)
<br> b. 회귀분석 : 함수관계를 통해 두 변수 사이의 상관관계를 파악할 수 있음, 독립변수의 변화에 따른 종속변수의 변화를 예측. (SSB로 선형함수 구하기)

### 선형회귀 분석
- 변수 간의 확률적 관계를 어떻게 표현할 수 있을까?
- Y = b0 + b1X, X변수와 Y변수 사이의 관계를 수치로 설명, 미래의 종속변수 값을 예측.
- 선형회귀모델 : 입력변수 X와 출력변수 Y들의 선형결합으로 표현한 모델
<br> 선형결합 : 변수들을 상수 배와 더하기 뺴기를 통해 결합
- 회귀계수 b1^의 해석은? X가 변화할때, Y의 평균 변화량

### 다중회귀분석
- Explanatory, 설명 : fit the data well and understand the contribution of explanatory variables to the model
- Predictive, 예측 : Optimize predictive accuracy

### 2. 선형회귀와 최소제곱법 (Ordinary least squares)
### 선형회귀모델
- Y = X로 설명되는 부분(b0 + b1X) + X로 설명 안되는 부분(ε, 오차항, 확률오차, random error)
- Least squares method, 최소제곱법 : 오차제곱합, (y-y^)^2를 최소화하는 y절편과 기울기를 찾는 것
<br> '최적화'에 경사하강법.

### 3. 선형회귀모형의 타당성 검토
### 모형의 타당성 검토
- 선형회귀모형의 가정
<br> 예측변수와 반응변수 간의 관계가 선형
<br> 오차항들이 서로 독립이며, 분산이 동일하고, 분포가 평균이 0인 정규분포
- 모형 추정 후 위 가정을 Residual, 잔차(ei = y - y^)분석을 통해 검토할 수 있음
- QQ Plot of Residual : 잔차의 정규성을 확인하는 그래프, 직선일 수록 정규성을 만족.
- 시간에 따라 관측한 자료에 대하여 관측순서에 따라 어떤 패턴이 있으면 독립이라고 볼 수 없으므로, 오차의 독립성이 훼손됐다면 시계열분석을 진행해야 함.
  - 오차의 등분산성 : y^i값에 따라서 ε^i값으ㅣ 등분산이 훼손될 경우, 변수변환으로 해결 가능

### 선형회귀모델 - 점 추정
- Least square estimator, 최소자승법은 하나의 값을 추정하는 점추정 기법
- 해석에는 용이하지만, 잘못된 값 추정시 부정확한 정보가 제공됨
- 구간으로 추정하여 보다 유연한 정보를 제공해야 함

### 선형회귀모델 - 구간 추정
- Interval Estimator, 구간추정기
- b0은 0이다, 0이 아니다 를 검증하여 x라는 factor를 고려해야 하는지, 아닌지 알 수 있다.
- 변수별로 '샘플을 기반으로 h0를 기각하기 위한 어떤 최소한의 유의수치인 p-value'를 본다.

### 선형회귀모델 - 결정 계수
- Coefficient of Determination, R^2, 결정 계수
<br> 회귀모델의 적합도를 판단할 수 있는 수치, Goodness-of-fit
- SST = SSR + SSE
<br> SST, Total Sum of Square : Σ(Yi-Ybar)^2, Y의 총 편차
<br> SSR, Regression Sum of Square : Σ(Y^-Ybar)^2, 회귀식으로 설명 가능한 편차
<br> SSE, Error Sum of Square : Σ(Yi-Y^)^2, 회귀식으로 설명 불가능한 편차, ε
<br> *Ybar 은 y의 임의의 점 지정.
- R^2, R-squared = SSR/SST = 1 - (SSE/SST)
<br> 직선이 데이터를 얼마나 설명해주나?
<br> R^2가 1에 가까울수록 강한 선형관계가 있다.
<br> ex) R^2 = 0.683 -> 설명력이 68.3% 있다.

## 예측성능 평가척도
### 선형회귀모델 - 성능평가
- 성능평가의 여러 방법론들
1. Average error : Σ(Y-Y^)/n
- 부호로 
- ㅇ

3. Mean Squared Error, MSE : Σ(Y-Y^)^2/n
4. Mean Absolute Deviation, MAD : Σ|Y-Y^|/n
5. Mean Absolute Percentage Error, MAPE : (Σ|Y-Y^/Y|/n)*100(%)



## 변수선택 방법
