# 선형회귀분석
## Prediction, 예측
### 예측이란?
- 과거의 정보로부터 설명변수 X와 반응변수 Y와의 함수관계 f(x)를 추정하여, 새로운 설명변수에 대해 예상된 연속형 결과변수 값

### 예측 vs 분류
- 연속형 변수 : 숫자로 측정 가능한 변수 ex) 온도, 압력, 가격 등 - regression model (예측)
- 범주형 변수 : 숫자의 의미가 없는 변수 ex) 불량여부(Y/N), 환자/정상 등 - classification model (분류)

### 예측모형 개요
- x에서 가능한 y값들의 평균 값을 예측치로 준다.

## Linear Regression, (다중) 선형 회귀모형
### 1. 선형회귀모델 개요
### 회귀분석
- 두 변수 간의 관계를 설명 가능한가?
<br> a. 상관분석 : 변수 사이에 의미 있는 상관관계가 있는지, 없는지 그 크기를 분석. (선형성 확인, 피어슨 상관계수)
<br> b. 회귀분석 : 함수관계를 통해 두 변수 사이의 상관관계를 파악할 수 있음, 독립변수의 변화에 따른 종속변수의 변화를 예측. (SSB로 선형함수 구하기)

### 선형회귀 분석
- 변수 간의 확률적 관계를 어떻게 표현할 수 있을까?
- Y = b0 + b1X, X변수와 Y변수 사이의 관계를 수치로 설명, 미래의 종속변수 값을 예측.
- 선형회귀모델 : 입력변수 X와 출력변수 Y들의 선형결합으로 표현한 모델
<br> 선형결합 : 변수들을 상수 배와 더하기 뺴기를 통해 결합
- 회귀계수 b1^의 해석은? X가 변화할때, Y의 평균 변화량

### 다중회귀분석
- Explanatory, 설명 : fit the data well and understand the contribution of explanatory variables to the model
- Predictive, 예측 : Optimize predictive accuracy

### 2. 선형회귀와 최소제곱법 (Ordinary least squares)
### 선형회귀모델
- Y = X로 설명되는 부분(b0 + b1X) + X로 설명 안되는 부분(ε, 오차항, 확률오차, random error)
- Least squares method, 최소제곱법 : 오차제곱합, (y-y^)^2를 최소화하는 y절편과 기울기를 찾는 것
<br> '최적화'에 경사하강법.

### 3. 선형회귀모형의 타당성 검토
### 모형의 타당성 검토
- 선형회귀모형의 가정
<br> 예측변수와 반응변수 간의 관계가 선형
<br> 오차항들이 서로 독립이며, 분산이 동일하고, 분포가 평균이 0인 정규분포
- 모형 추정 후 위 가정을 Residual, 잔차(ei = y - y^)분석을 통해 검토할 수 있음
- QQ Plot of Residual : 잔차의 정규성을 확인하는 그래프, 직선일 수록 정규성을 만족.
- 시간에 따라 관측한 자료에 대하여 관측순서에 따라 어떤 패턴이 있으면 독립이라고 볼 수 없으므로, 오차의 독립성이 훼손됐다면 시계열분석을 진행해야 함.
  - 오차의 등분산성 : y^i값에 따라서 ε^i값으ㅣ 등분산이 훼손될 경우, 변수변환으로 해결 가능

### 선형회귀모델 - 점 추정
- Least square estimator, 최소자승법은 하나의 값을 추정하는 점추정 기법
- 해석에는 용이하지만, 잘못된 값 추정시 부정확한 정보가 제공됨
- 구간으로 추정하여 보다 유연한 정보를 제공해야 함

### 선형회귀모델 - 구간 추정
- Interval Estimator, 구간추정기
- b0은 0이다, 0이 아니다 를 검증하여 x라는 factor를 고려해야 하는지, 아닌지 알 수 있다.
- 변수별로 '샘플을 기반으로 h0를 기각하기 위한 어떤 최소한의 유의수치인 p-value'를 본다.

### 선형회귀모델 - 결정 계수
- Coefficient of Determination, R^2, 결정 계수
<br> 회귀모델의 적합도를 판단할 수 있는 수치, Goodness-of-fit
- SST = SSR + SSE
<br> SST, Total Sum of Square : Σ(Yi-Ybar)^2, Y의 총 편차
<br> SSR, Regression Sum of Square : Σ(Y^-Ybar)^2, 회귀식으로 설명 가능한 편차
<br> SSE, Error Sum of Square : Σ(Yi-Y^)^2, 회귀식으로 설명 불가능한 편차, ε
<br> *Ybar 은 y의 임의의 점 지정.
- R^2, R-squared = SSR/SST = 1 - (SSE/SST)
<br> 직선이 데이터를 얼마나 설명해주나?
<br> R^2가 1에 가까울수록 강한 선형관계가 있다.
<br> ex) R^2 = 0.683 -> 설명력이 68.3% 있다.

## 예측성능 평가척도
### 선형회귀모델 - 성능평가
- 성능평가의 여러 방법론들
1. Average error : Σ(Y-Y^)
- 부호로 인해 실제값보다 과대/과소 평가할 수 있음
2. Mean Squared Error, MSE : Σ(Y-Y^)^2/n
- 제곱하여 부호의 영향을 제거함, root씌우면 RMSE
3. Mean Absolute error, MAE : Σ|Y-Y^|/n
- 절대적인 오차의 평균을 이용
'4'. Mean Absolute Percentage Error, 'MAPE' : (Σ|Y-Y^/Y|/n)*100(%)
- MAE + percentage

## 변수선택 방법
### 변수선택의 필요성
- 일반적으로 반응변수에 영향을 미칠 것으로 예상되는 예측변수들은 많지만, 유의한 영향을 미치는 변수는 많지 않음
- feature 갯수가 많아질수록, model의 복잡도가 높아지며 overfitting 될 가능성이 높아짐. 예측오차가 더 커지는 결과가 되므로, 유의미한 소수의 feature만 선택하는 것이 필요함. trade-off 관계.
- 너무 상관관계가 높은 feature 두개를 같이 선택하면, 각 파라미터가 하나의 변수만 설명하지 못하여 문제가 됨.

### 변수선택 절차
- p개의 feature로 예측변수가 1개 있는 모형부터 M0, M1,,, Mp를 만든 뒤, 이중 가장 좋은 모형을 선택한다. 모형 선택의 기준은 AIC(Akaike Information Criteria), 수정된 결정계수(Adjust coefficient of determination, 'R^2adj'), Mallow's Cp 등이 사용 됨

### 변수선택
- (p+1)개의 모형 M0, M1,,, Mp에서 R^2adj를 비교하여 선택하는 방법들은 아래와 같음.
#### 1. All possible regression, 가능한 모든 회귀모형 탐색법
- 모든 모형 ... 2^P개의 모형
- 가장 많은 cost가 소요 되는 반면, 가장 정확한 방법이지만 사용하지 않음.

#### 2. Foward selection method, 전진 선택법
- M0와 M1 비교 -> 선택된 M1과 M1이 포함된 M2 비교 -> ... p(p+1)/2개의 모형
- 일정이상 커지지 않으면 진행되지 않으며, 한번 선택된 변수는 절대로 제거되지 않는다는 단점이 있음.

#### 3. Backward selection method, 후진 소거법
- Mp와 Mp-1 비교 -> 선택된 Mp-1과 Mp-2 비교 -> ... p(p+1)/2개의 모형
- 일정이상 커지지 않으면 진행되지 않으며, 한번 제거된 변수는 절대로 선택되지 않는다는 단점이 있음.

#### 4. Stepwise selection method, 단계적 선택법
- Forward + Backward로, 매 단계마다 선택과 제거를 반복하면서 진행됨.
- 중요한 변수를 하나씩 추가로 선택하면서 이미 선택된 변수들이 제거될 수 있는지 매단계 검토함.

### Adjusted-R^2, 수정 결정계수
- R^2adj = 1 - ((n-1)/(n-p)) (1-R^2), n : 표본 수, p : 독립변수 수
<br> R^2는 유의하지 않은 변수가 추가되어도 항상 증가하는 것이 문제점
<br> Adjusted-R^2는 표본크기와 독립변수의 수를 추가 고려하여 위의 문제점을 보정.
- 
- R^2는 0~1까지이지만, R^2adj는 0보다 작은 값이 나오기도 하는데 음수의 의미는 회귀모형을 사용할 수 없으며 모형이 적합하지 않다는 뜻
- 또한 R^2보다 R^2adj가 크게 작다면 모형에 불필요한 독립변수가 있다는 것으로 해석 가능.






