{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Machine (SVM)\n",
    "\n",
    "# 간단한 예시\n",
    "# Import Libraries\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate some (random) data\n",
    "data = np.array([[1, -1], [2, -2], [0, 1], [-1, 2]])\n",
    "label = np.array([1, 1, -1, -1])\n",
    "plt.scatter(data[:,0], data[:,1], c=label, s=50, cmap='spring')\n",
    "plt.show()\n",
    "\n",
    "# Train SVM\n",
    "svmmodel = svm.SVC(kernel='linear') # C값이 클수록 error를 허용하지 않겠다는 뜻이므로, 과도하게 크면 overfitting 된다.\n",
    "svmmodel.fit(data, label)\n",
    "svmmodel.support_    # indices of support vectors, 어느 인덱스가 서포트 벡터인지 / 첫번째, 세번쨰니까 0, 2\n",
    "svmmodel.support_vectors_    # 인덱스 말고 support vectors 직접 확인하기\n",
    "svmmodel.coef_    # a weight vector w (size: # of features)\n",
    "svmmodel.intercept_    # bias (w0)\n",
    "\n",
    "# 선 그어서 시각화\n",
    "w = svmmodel.coef_[0]\n",
    "slope = -w[0] / w[1]\n",
    "margin = 1 / np.sqrt(np.sum(w ** 2)) # sqrt : 제곱근\n",
    "\n",
    "xx = np.linspace(-5,5)\n",
    "yy = slope * xx - svmmodel.intercept_[0] / w[1]        # decisoin boundary\n",
    "yy1 = slope * xx - svmmodel.intercept_[0] / w[1] + margin    # margin\n",
    "yy2 = slope * xx - svmmodel.intercept_[0] / w[1] - margin    # margin\n",
    "\n",
    "print(xx.shape)\n",
    "print(yy.shape)\n",
    "\n",
    "plt.scatter(data[:,0], data[:,1], c=label, s=50, cmap='spring')\n",
    "plt.plot(xx, yy, 'r')\n",
    "plt.plot(xx, yy1, 'r--')\n",
    "plt.plot(xx, yy2, 'r--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 복잡한 예시\n",
    "# Import Libraries\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate some (random) data\n",
    "X, Y = datasets.make_blobs(400, 2, centers=2, random_state=3, cluster_std=1.0)\n",
    "TrainX, TestX, TrainY, TestY = train_test_split(X, Y, test_size=0.3, random_state=0)\n",
    "plt.scatter(TrainX[:,0], TrainX[:,1], c=TrainY, s=50, cmap='spring')\n",
    "plt.show()\n",
    "\n",
    "# Train SVM\n",
    "svmmodel = svm.SVC(kernel='linear')\n",
    "svmmodel.fit(TrainX, TrainY)\n",
    "\n",
    "# Let's check out the parameters of SVM\n",
    "svmmodel.support_    # indices of support vectors\n",
    "svmmodel.support_vectors_    # support vectors\n",
    "svmmodel.coef_    # a weight vector w (size: # of features)\n",
    "svmmodel.intercept_    # bias (w0)\n",
    "\n",
    "# 선 그어서 시각화\n",
    "w = svmmodel.coef_[0]\n",
    "slope = -w[0] / w[1]\n",
    "margin = 1 / np.sqrt(np.sum(w ** 2))\n",
    "\n",
    "xx = np.linspace(-5,5)\n",
    "yy = slope * xx - svmmodel.intercept_[0] / w[1]        # decisoin boundary\n",
    "yy1 = slope * xx - svmmodel.intercept_[0] / w[1] + margin    # margin\n",
    "yy2 = slope * xx - svmmodel.intercept_[0] / w[1] - margin    # margin\n",
    "\n",
    "print(xx.shape)\n",
    "print(yy.shape)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(TrainX[:,0], TrainX[:,1], c=TrainY, s=50, cmap='spring')\n",
    "plt.scatter(TestX[:,0], TestX[:,1], c=TestY, marker='d', s=50, cmap='RdYlBu')\n",
    "plt.plot(xx, yy, 'r')\n",
    "plt.plot(xx, yy1, 'r--')\n",
    "plt.plot(xx, yy2, 'r--')\n",
    "plt.show()\n",
    "\n",
    "# Performance Evaluation, Accuracy\n",
    "from sklearn import metrics\n",
    "\n",
    "tr_pred = svmmodel.predict(TrainX)\n",
    "tr_acc = metrics.accuracy_score(TrainY, tr_pred)\n",
    "\n",
    "ts_pred = svmmodel.predict(TestX)\n",
    "ts_acc = metrics.accuracy_score(TestY, ts_pred)\n",
    "\n",
    "print('Training Accuracy : ', tr_acc)\n",
    "print('Test Accuracy : ', ts_acc)\n",
    "\n",
    "# Confusion Matrix\n",
    "tr_cmat = metrics.confusion_matrix(TrainY, tr_pred)\n",
    "print(tr_cmat)\n",
    "\n",
    "ts_cmat = metrics.confusion_matrix(TestY, ts_pred)\n",
    "print(ts_cmat)\n",
    "\n",
    "# ROC & AUC analysis\n",
    "# label이 아닌, hyperplane과 data 사이의 거리에 따른 실제 값을 알아야 계산 가능\n",
    "svmmodel = svm.SVC(kernel='linear', probability=True)\n",
    "svmmodel.fit(TrainX, TrainY)\n",
    "\n",
    "tr_score = svmmodel.predict_proba(TrainX)\n",
    "ts_score = svmmodel.predict_proba(TestX)\n",
    "\n",
    "tr_fpr, tr_tpr, tr_th = metrics.roc_curve(TrainY, tr_score[:,1], pos_label=1)\n",
    "ts_fpr, ts_tpr, ts_th = metrics.roc_curve(TestY, ts_score[:,1], pos_label=1)\n",
    "\n",
    "plt.plot(tr_fpr, tr_tpr, 'b:', linewidth=10, label='Train')\n",
    "plt.plot(ts_fpr, ts_tpr, 'r--', linewidth=5, label='Test')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "tr_auc = metrics.roc_auc_score(TrainY, tr_score[:,1])\n",
    "print('Training AUC : ', tr_auc)\n",
    "\n",
    "ts_auc = metrics.roc_auc_score(TestY, ts_score[:,1])\n",
    "print('Test AUC : ', ts_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Breast Cancer Wisconsin (Diagnostic) Dataset**\n",
    "# 569 instances (212 Malignant(악성종양), 357 Benign(양성종양))\n",
    "# 30 numerical features (computed from a digitized image of a breast mass)\n",
    "# 2 classes (Malignant, Benign)\n",
    "\n",
    "# Import Libraries\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 데이터 가져오고, Train 30%, test 70% 나누기\n",
    "wisconsin = datasets.load_breast_cancer()\n",
    "TrainX, TestX, TrainY, TestY = train_test_split(wisconsin.data, wisconsin.target, test_size=0.7, random_state=0)\n",
    "\n",
    "# Train SVM\n",
    "# svmmodel = svm.SVC(kernel=\"linear\")\n",
    "svmmodel = svm.SVC(kernel=\"linear\", probability=True)\n",
    "svmmodel.fit(TrainX, TrainY)\n",
    "\n",
    "# Accuracy\n",
    "tr_pred = svmmodel.predict(TrainX)\n",
    "tr_acc = metrics.accuracy_score(TrainY, tr_pred)\n",
    "\n",
    "ts_pred = svmmodel.predict(TestX)\n",
    "ts_acc = metrics.accuracy_score(TestY, ts_pred)\n",
    "\n",
    "print('Training Accuracy : ', tr_acc)\n",
    "print('Test Accuracy : ', ts_acc)\n",
    "\n",
    "# Confusion Matrix\n",
    "tr_cmat = metrics.confusion_matrix(TrainY, tr_pred)\n",
    "print(tr_cmat)\n",
    "\n",
    "ts_cmat = metrics.confusion_matrix(TestY, ts_pred)\n",
    "print(ts_cmat)\n",
    "\n",
    "# ROC & AUC analysis\n",
    "tr_score = svmmodel.predict_proba(TrainX)\n",
    "ts_score = svmmodel.predict_proba(TestX)\n",
    "\n",
    "tr_fpr, tr_tpr, tr_th = metrics.roc_curve(TrainY, tr_score[:,1], pos_label=1)\n",
    "ts_fpr, ts_tpr, ts_th = metrics.roc_curve(TestY, ts_score[:,1], pos_label=1)\n",
    "\n",
    "plt.plot(tr_fpr, tr_tpr, 'b:', linewidth=5, label='Train')\n",
    "plt.plot(ts_fpr, ts_tpr, 'r--', linewidth=5, label='Test')\n",
    "plt.xlim([0.0, 0.3])\n",
    "plt.ylim([0.7, 1.0])\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parkinson's Disease Dataset\n",
    "\n",
    "# Speech dataset from Parkinson's Disease (PD) patients and healthy subjects\n",
    "# 26 features computed from speech recordings\n",
    "# Training dataset: 300 instances (150 PD, 150 healthy)\n",
    "# Test dataset: 300 instances (150 PD, 150 healthy)\n",
    "\n",
    "# Training dataset: 'PD_train_smalldata.csv'\n",
    "# Test dataset: 'PD_test_smalldata.csv'\n",
    "\n",
    "# Import Libraries\n",
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# CSV data 확인 / TrainX, TrainY에 CSV 데이터 담기\n",
    "tr_dataset = pd.read_csv(\"./PD_train_smalldata.csv\")\n",
    "tr_dataset\n",
    "\n",
    "sum(tr_dataset.Class == 0) # class0 인거 몇개?\n",
    "\n",
    "TrainX = tr_dataset.iloc[:, :-1] # pandas lib, 데이터의 일부 가져오기. 맨 뒤에 class 잘라내기\n",
    "TrainY = tr_dataset.Class\n",
    "\n",
    "ts_dataset = pd.read_csv(\"./PD_test_smalldata.csv\")\n",
    "ts_dataset\n",
    "\n",
    "TestX = ts_dataset.iloc[:, :-1]\n",
    "TestY = ts_dataset.Class\n",
    "\n",
    "# Normalize Data : Rescale the range of the values\n",
    "# 0-1 range : rescale the values between 0 and 1 / 0~1사이에 다 넣기 -> x-xm / xM-xm\n",
    "# 큰 값에 작은 값들이 영향을 받는다. model이 큰 값들에만 집중하게 됨. 따라서 그대로 쓰면 안되고, 정규화 진행하는것을 권장.\n",
    "\n",
    "# 각 feature들의 max, min 확인. 어 너무 차이가 큰데? 정규화 가자.\n",
    "plt.plot(np.arange(0,26), TrainX.min(), 'b')\n",
    "plt.plot(np.arange(0,26), TrainX.max(), 'r')\n",
    "plt.show() \n",
    "\n",
    "# Normalize\n",
    "TrainXmin = TrainX.min()\n",
    "TrainXmax = TrainX.max()\n",
    "\n",
    "TrainX = (TrainX - TrainXmin) / (TrainXmax - TrainXmin)\n",
    "TestX = (TestX - TrainXmin) / (TrainXmax - TrainXmin) # 분모가 Test가 이님. *주의*\n",
    "\n",
    "plt.plot(np.arange(0,26), TrainX.min(), 'b')\n",
    "plt.plot(np.arange(0,26), TrainX.max(), 'r')\n",
    "plt.show() # max, min이 모두 1, 0으로 된 것 확인 가능하다. = 정규화 완료\n",
    "\n",
    "# Train SVM\n",
    "svmmodel = svm.SVC(kernel=\"linear\", probability=True)\n",
    "svmmodel.fit(TrainX, TrainY)\n",
    "\n",
    "# Performance Evaluation, Accuracy\n",
    "tr_pred = svmmodel.predict(TrainX)\n",
    "tr_acc = metrics.accuracy_score(TrainY, tr_pred)\n",
    "\n",
    "ts_pred = svmmodel.predict(TestX)\n",
    "ts_acc = metrics.accuracy_score(TestY, ts_pred)\n",
    "\n",
    "print('Training Accuracy : ', tr_acc)\n",
    "print('Test Accuracy : ', ts_acc)\n",
    "# = linear만 사용하니까 acc값이 너무 낮다.\n",
    "\n",
    "# Confusion Matrix\n",
    "tr_cmat = metrics.confusion_matrix(TrainY, tr_pred)\n",
    "print(tr_cmat)\n",
    "\n",
    "ts_cmat = metrics.confusion_matrix(TestY, ts_pred)\n",
    "print(ts_cmat)\n",
    "\n",
    "# ROC & AUC analysis\n",
    "tr_score = svmmodel.predict_proba(TrainX)\n",
    "ts_score = svmmodel.predict_proba(TestX)\n",
    "\n",
    "tr_fpr, tr_tpr, tr_th = metrics.roc_curve(TrainY, tr_score[:,1], pos_label=1)\n",
    "ts_fpr, ts_tpr, ts_th = metrics.roc_curve(TestY, ts_score[:,1], pos_label=1)\n",
    "\n",
    "plt.plot(tr_fpr, tr_tpr, 'b:', linewidth=5, label='Train')\n",
    "plt.plot(ts_fpr, ts_tpr, 'r--', linewidth=5, label='Test')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "# Kernel을 변경하기 용이하도록 function 정의\n",
    "def SVMmodel(TrainX, TrainY, TestX, TestY, kernel=\"rbf\"):\n",
    "  svmmodel = svm.SVC(kernel=kernel, probability=True)\n",
    "  svmmodel.fit(TrainX, TrainY)\n",
    "\n",
    "  tr_pred = svmmodel.predict(TrainX)\n",
    "  tr_acc = metrics.accuracy_score(TrainY, tr_pred)\n",
    "\n",
    "  ts_pred = svmmodel.predict(TestX)\n",
    "  ts_acc = metrics.accuracy_score(TestY, ts_pred)\n",
    "\n",
    "  print('Training Accuracy : ', tr_acc)\n",
    "  print('Test Accuracy : ', ts_acc)\n",
    "\n",
    "  tr_score = svmmodel.predict_proba(TrainX)\n",
    "  ts_score = svmmodel.predict_proba(TestX)\n",
    "\n",
    "  tr_fpr, tr_tpr, tr_th = metrics.roc_curve(TrainY, tr_score[:,1], pos_label=1)\n",
    "  ts_fpr, ts_tpr, ts_th = metrics.roc_curve(TestY, ts_score[:,1], pos_label=1)\n",
    "\n",
    "  plt.plot(tr_fpr, tr_tpr, 'b:', linewidth=5, label='Train')\n",
    "  plt.plot(ts_fpr, ts_tpr, 'r--', linewidth=5, label='Test')\n",
    "  plt.legend(loc='best')\n",
    "  plt.show()\n",
    "\n",
    "  tr_auc = metrics.roc_auc_score(TrainY, tr_score[:,1])\n",
    "  print('Training AUC : ', tr_auc)\n",
    "\n",
    "  ts_auc = metrics.roc_auc_score(TestY, ts_score[:,1])\n",
    "  print('Test AUC : ', ts_auc)\n",
    "\n",
    "# Kernel 변경하여 더 좋은 model 찾기\n",
    "\n",
    "# Linear Kernel\n",
    "# 아무것도 안하겠다.\n",
    "SVMmodel(TrainX, TrainY, TestX, TestY, kernel=\"linear\")\n",
    "\n",
    "# Radial Bias Function Kernel\n",
    "# 기본설정값, gamma값이 C값과 역할이 비슷하다. 커지면 trainning data에 더 높은 중요도롤 줘서 overfitting.\n",
    "SVMmodel(TrainX, TrainY, TestX, TestY, kernel=\"rbf\")\n",
    "\n",
    "# Polynomial Kernel (2D -> 3D)\n",
    "# linear하게 구분되지 않는 데이터들을 다른 공간으로 projection시켜서 구분할 수 있게 만든다.\n",
    "SVMmodel(TrainX, TrainY, TestX, TestY, kernel=\"poly\")\n",
    "\n",
    "# 시간날 떄 읽어보자 : https://ekdud7667.tistory.com/entry/SVM1"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "53e118947077c4ac14cd9b5bd8ffefe9287941f870ede6c6d93932b2f5dedd6a"
  },
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit ('test1': conda)",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
